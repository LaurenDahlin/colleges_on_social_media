{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Scrape Tweets of Twitter Users (Handles) and Get Around Twitter API Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Get entire history of tweets for particular Twitter users using their handles. Avoid any limits put in place by the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step I compiled a list of all the Twitter handles from colleges in our sample on Twitter. The next step is to obtain all tweets created by each handle. This is tricky because the Twitter API [limits the number of Tweets you can pull](https://developer.twitter.com/en/docs/basics/rate-limiting.html). Thankfully, the developers of the [twint](https://github.com/twintproject/twint) Python package have figured out how to circumvent these limits by not using the API at all!\n",
    "\n",
    "All tweets are output to a .json file for each college's main handle and admissions handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, requests, re, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\laure\\Dropbox\\!research\\20181026_ihe_diversity\"\n",
    "tw_path = os.path.join(base_path,'data','twitter_handles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihe_handles = pd.read_pickle(os.path.join(tw_path, \"tw_df_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instnm</th>\n",
       "      <th>main_handle</th>\n",
       "      <th>adm_handle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154022</th>\n",
       "      <td>Ashford University</td>\n",
       "      <td>AshfordU</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133951</th>\n",
       "      <td>Florida International University</td>\n",
       "      <td>fiu</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  instnm main_handle adm_handle\n",
       "unitid                                                         \n",
       "154022                Ashford University    AshfordU           \n",
       "133951  Florida International University         fiu           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihe_handles[ihe_handles.adm_handle == ''].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape All Tweets from Username with Twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(username, csv_name):\n",
    "    # Configure\n",
    "    c = twint.Config()\n",
    "    c.Username = username\n",
    "    c.Custom = ['id', 'date', 'time', 'timezone', 'user_id', 'username', 'tweet', 'replies', \n",
    "                'retweets', 'likes', 'hashtags', 'link', 'retweet', 'user_rt', 'mentions']\n",
    "    c.Store_csv = True\n",
    "    c.Output = os.path.join(tw_path, csv_name)\n",
    "    \n",
    "    # Start search\n",
    "    twint.run.Profile(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ihe_handles.iterrows():\n",
    "    \n",
    "    # CSV file names\n",
    "    main_f_name = os.path.join(tw_path, str(index) + '_main.csv')\n",
    "    adm_f_name = os.path.join(tw_path, str(index) + '_adm.csv')\n",
    "    \n",
    "    # Handles\n",
    "    main_handle = row['main_handle']\n",
    "    adm_handle = row['adm_handle']\n",
    "    \n",
    "    if main_handle != '':\n",
    "        scrape_tweets(main_handle, main_f_name)\n",
    "    \n",
    "    if adm_handle != '':\n",
    "        scrape_tweets(adm_handle, adm_f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
